%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Origin of this template:
%% https://authors.acm.org/proceedings/production-information

%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0

%% DOCUMENT CLASS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[sigconf]{acmart}
% \documentclass[manuscript, screen, review]{acmart}


%% PACKAGES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{csquotes}
\usepackage{fancyhdr}
\usepackage{changepage}

%% SETTINGS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Remove identation on "double-linebreaks".
\setlength{\parindent}{0pt}


%% LICENSE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Remove all the licence, conference, ISBN and DOI information that are the
%% default for this template.
\settopmatter{printacmref=false} % Removes citation information below abstract
\settopmatter{printfolios=true} % Adds page numbers (optional, for review)
\renewcommand\footnotetextcopyrightpermission[1]{} % Removes conference footnote

% TODO: How to remove the conference from the page header?
% \acmConference[ ]{ }{ }{ }

%% CITATION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% The majority of ACM publications use numbered citations and references.
%% The command \citestyle{authoryear} switches to the "author year" style.
%%
%% If you are preparing content for an event sponsored by ACM SIGGRAPH, you must
%% use the "author year" style of citations and references.
%% Uncommenting the next command will enable that style.
% \citestyle{acmauthoryear}

%% BEGIN %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% End of the preamble, start of the body of the document source.
\begin{document}

%% TITLE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% The "title" command has an optional parameter,
% \title{Genetic Algorithms for Timetabling: The current state of the art}
\title{Overview of Genetic Algorithms in Educational Timetabling}

%% AUTHORS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author{Luca Quaer}
\email{luca@quaer.net}
\affiliation{
  \institution{Wilhelm Büchner Hochschule}
  \city{Darmstadt}
  \state{Baden-Württemberg}
  \country{Germany}
}

% \author{John Doe}
% \email{john@doe.net}

% \affiliation{
%   \institution{Massachusetts Institute of Technology}
%   \city{Cambridge}
%   \state{MA 02139}
%   \country{United States of America}
% }


%% DATES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}


%% ABSTRACT %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
Educational timetabling is a complex optimization problem common to
academic institutions such as schools, colleges and universities.
It is a NP-complete combinatorial optimization problem, which requires
efficient allocation of resources like classrooms and instructors to various
activities within educational institutions.
This paper examines the application of genetic algorithms addressing such
timetabling problems, leveraging their ability to effectively explore large
solution spaces.

The study provides a comprehensive analysis of the current state of research on
genetic algorithms in educational timetabling, highlighting prevalent
techniques and identifying underutilized strategies like parallelism and
adaptive evolutionary strategies, emphasizing the potential for innovation in
solving timetabling problems.

Through a systematic literature review and discussion, the paper identifies
trends and areas for future research, underscoring the importance of exploring
innovative techniques to enhance the efficiency of genetic algorithms in
addressing timetabling complexities. The findings contribute to advancing
timetabling practices, exploring new methodologies and combinations of
characteristics to ultimately push innovation in the field, increase
the utilization of genetic algorithms and their effectiveness specifically
in the domain of educational timetabling.

% In conclusion, this research sheds light on the effectiveness of genetic
% algorithms in educational timetabling and underscores the potential for further
% exploration and innovation in the field.
% By leveraging the strengths of genetic algorithms and exploring new
% methodologies, researchers can improve timetabling processes, leading to better
% resource allocation and enhanced educational experiences.

\end{abstract}


%% KEYWORDS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Genetic Algorithms, Educational Timetabling, Metaheuristics}


%% TITLE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\maketitle


%% CONTENT %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Introduction ------------------------------------------------------------- %%
\section{Introduction}
% What is educational timetabling
Educational timetabling involves creating schedules for educational
institutions such as schools, colleges, and universities.
The problem domain can be divided into the following three main problems
\cite{kingston2013educational,schaerf1999survey}:
High-School Timetabling (HSTP), University Course Timetabling (UCTP) and
University Examination Timetabling (ETT).
Although a clear distinction between these three problems is not always
possible, they generally differ significantly from one another
\cite{Beligiannis2009}.
However, each of these problems essentially is a resource allocation problem
with the goal of assigning classrooms, instructors, and students to specific
time slots for various courses or activities, ensuring that all constraints and
requirements are met.
This includes avoiding conflicts (e.g., a student being scheduled for two
classes at the same time), adhering to institutional policies, and maximizing
the efficient use of resources.

% Why is it complicated?
The difficulty in finding a valid and effective solution to such a problem
lies in meeting the diverse requirements of different stakeholders
(e.g. students, teachers, administration), multiple constraints and resolving
resource conflicts in a combinatorial complex solution space caused by the
numerous constraints.
Timetabling problems like these are therefore known to be NP-complete in their
general form, meaning that the difficulty of finding a solution increases
exponentially with the problem size, which in turn makes it impossible to find
a deterministic algorithm providing an acceptable solution in polynomial time
\cite{Beligiannis2009}.
%
% What are solutions to the problem?
One popular approach to addressing the complexity of timetabling problems is the
use of metaheuristic algorithms \cite{Beligiannis2009}.
This class of algorithms leverages a non-deterministic search approach which
compromises on finding an optimal solution in favor of better runtime
performance. Consequently, such algorithms are not guaranteed to find
the best solution for a given problem, but a near optimal one
\cite{Affenzeller2009}.
Despite this limitation, metaheuristic algorithms are widely used in educational
timetabling due to their ability to provide high-quality solutions within
a reasonable timeframe.
These algorithms can be broadly classified into two categories: single-solution
and population-based metaheuristics \cite{Katoch2021}.
Single-solution based algorithms use a single candidate solution and iteratively
improve it by using local search, but are prone to get stuck in local maxima
\cite{Katoch2021}.
Population-based metaheuristics on the other hand work on multiple candidate
solutions during the search process, avoiding the risk of getting stuck
in a local maximum by maintaining diversity among the solution candidates
\cite{Katoch2021}.
Popular single-solution based algorithms in the timetabling domain are
simulated annealing, local search and Tabu search
\cite{Ceschia2023, Katoch2021}.
Well-known population based metaheuristics are genetic algorithms, particle
swarm optimization and ant colony systems \cite{Beligiannis2009, Katoch2021}.

% Solving problems of such complexity in a practicable timeframe is therefore
% mostly done by using metaheuristic algorithms, which find solutions to
% optimization problems but are not guaranteed to find the best solution.
% Therefore, optimization algorithms trying to find (near) optimal solutions have
% been used as alternative methods of solving educational timetabling problems.
% Examples for such methods are local search and simulated annealing techniques
% as well as computational intelligence algorithms like genetic algorithms (GAs),
% Tabu Search, Ant Systems and other metaheuristic approaches
% \cite{Beligiannis2009}.

% The algorithm of interest; Why are GAs well suited for timetabling?
Among these methods, genetic algorithms are known for their versatility and
application in a variety of use cases with the need of searching for solutions
of a combinatorial problem in a large solution space.
Therefore, this paper specifically focuses on genetic algorithms and how they
are used in the domain of educational timetabling.

% What is a GA?
Genetic algorithms (abbr. \textit{GA}) are a heuristic search method inspired by
the process of natural selection in biological evolution and thus belong to
the group of evolutionary algorithms \cite{Katoch2021}. As mentioned previously,
genetic algorithms utilize a population based approach, meaning multiple
solution candidates are iteratively evolved through numerous generations
imitating the Darwinian theory of survival of the fittest \cite{Katoch2021}.

% Introduce structure here? Or better do this in the "Methods" chapter?


%% Methods ------------------------------------------------------------------ %%
\section{Methods}
%% Intro
Publications in the past, especially survey papers, in the field of educational
timetabling, showed a shift from meta-heuristic methods like genetic algorithms
towards mathematical optimization methods in the recent years
\cite{Tan2021}.
%
Consequently, a research gap in the field of educational timetabling
with regard to genetic algorithms opened up.
%
This may seem like genetic algorithms are not suitable in this domain,
but research shows, that genetic algorithms have proven their effectiveness
in solving timetabling problems \cite{Rezaeipanah2019,Chen2021}.
%
The decreasing utilization of genetic algorithms could be the result of
researchers not using the best algorithm to solve a problem but rather
methodologies they already have experience with \cite{Ceschia2023}.

%% What this paper does
This paper analyzes the current use of genetic algorithms with focus on
approaches to solve educational timetabling problems.
% Presenting these results the reader will have a good overview of ...
%
The basis for this is a comprehensive systematic literature research that
was carried out in order to identify as many relevant applications of genetic
algorithms in the domain of educational timetabling as possible, and
present their most crucial characteristics.
%
Several scientific databases such as IEEE Xplore, ACM Digital Library,
SpringerLink and Google Scholar were searched with prominent keywords such as
\enquote{educational timetabling}, \enquote{timetabling}, \enquote{scheduling},
\enquote{heuristic} and \enquote{meta-heuristic}.
%
In order to provide a comprehensive overview of the development and use of
genetic algorithms in this field, care was taken to give preference to recent
publications. However, older, established studies and papers were also taken
into account in order to ensure that no methods already in use were excluded
only due to their age.
%
Nevertheless, the primary objective was to provide a comprehensive and detailed
description of the algorithms, with the aim of documenting its properties.
This objective is not consistently met in many publications, particularly
when the algorithm was deliberately not published and therefore only rough
details were disclosed and only results have been discussed.


%% Structure of the paper
This paper is structured as follows:
First, the fundamentals of genetic algorithms and selected advanced concepts
are presented. Introducing some basic concepts serves to better understand the
properties of the algorithms, which are presented in the discussion section
of the paper. The selected concepts which are part of the introduction give
a good overview of genetic search, but cannot be an exhaustive coverage of the
all developments and research in this field.
%
After the introduction, the algorithms identified in the literature research
are then presented in a morphological box in combination with their most
important characteristics.
This provides an overview of the current state of research on genetic algorithms
for educational timetabling and also highlights possible research approaches
to be taken, by creating combination of algorithm properties, which have not
been used in this constellation.
The systematic analysis and presentation in form of a morphological box is
intended to inspire practitioners and researchers to develop innovative
and effective approaches and to further develop existing methods.
%
Finally, the overarching findings from the literature research are used to
assess the potential success of genetic algorithms in future research.


%% Basic Concepts ----------------------------------------------------------- %%
\section{Basic Concepts}
Genetic algorithms are a type of search and optimization algorithm inspired
by the biological process of reproduction and natural selection and represent
one branch in the field of evolutionary computing \cite{goldberg1989, Carr2014}.

In the search for a solution to an optimization problem, the set of possible
solutions -- the so-called solution space -- must first be determined and made
comprehensible for an algorithm in form of a data structure, which is suitable
for representing a solution \cite{Affenzeller2009}.
This representation of the solution is also called \textit{encoding} and
contains the data of a possible solution to the problem to be solved.
In nature, this data is encoded on chromosomes. Similarly, in genetic algorithms
the possible solution in coded form is also called \textit{chromosome} or
\textit{individual} \cite{Affenzeller2009}.

In addition, genetic algorithms employ a population based search approach,
whereby instead of a single potential solution a whole set of solutions is
iteratively improved. Such a set of solutions is called \textit{population}
and consists of multiple chromosomes. The stages of iterative improvements
are called \textit{generations} \cite{Affenzeller2009}.

In order for the algorithm to optimize towards a desired solution, it is
necessary to have a measure in place to evaluate and compare the chromosomes.
This value referred to as \textit{fitness} and is provided by the
\textit{fitness function} (also called \textit{objective function})
\cite{Affenzeller2009}.

With these basic terms defined, the general process of genetic algorithms
can now be described as follows:
First, an \textit{initial population} must be created and the fitness of its
chromosomes must be evaluated \cite{Affenzeller2009}.
Pairs (or triples, quadruples, etc.) are then selected
(\textit{selection} phase) from this population in order to reproduce
(known as \textit{crossover}) \cite{Affenzeller2009}.
The resulting offspring may undergo one or more mutations
(\textit{mutation} phase) with a defined probability before the fitness of
these new chromosomes is determined (\textit{evaluation} phase)
\cite{Affenzeller2009}.
Based on certain criteria chromosomes from the current generation and their
offspring are now selected, to replace the population with a new one
(\textit{replacement} phase) \cite{Affenzeller2009}.
The result of this step is a new generation of chromosomes forming a new
(usually fitter) population \cite{Affenzeller2009}.
From this population, chromosomes are once again selected for reproduction,
starting the process all over again \cite{Affenzeller2009}.
The genetic algorithm could theoretically continue indefinitely according to
this pattern, with termination conditions serving as the only means of halting
the process \cite{Beligiannis2009}.
%
The forementioned phases of genetic algorithms will be explained in the
following chapters.

%%% Encoding %%%
\subsection{Encoding}
Genetic algorithms require two essential components: an encoding and
a fitness function \cite{Affenzeller2009}.
The encoding plays a pivotal role in the design of a genetic algorithm
\cite{Katoch2021}.
Its most significant property is that it can completely represent the solution
space of the problem at hand, thereby deriving the potential solution to the
problem from a given chromosome \cite{Affenzeller2009}.
Moreover, the encoding must be designed in consideration of the data
processing of other genetic algorithm components, such as the fitness function
and the crossover operator \cite{Affenzeller2009}.
The fitness function must calculate the fitness value based on this
representation of a solution candidate, and the crossover operator should
generate offspring that are as valid as possible \cite{Affenzeller2009}.
In particular, the latter aspect can often only be fulfilled by an adapted,
domain-specific representation \cite{Affenzeller2009}.
%
The following paragraphs present some well-known encodings.

\subsubsection{Binary Encoding}
Binary encoding is a method in which chromosomes are represented as strings
of binary digits, i.e. an array of 0s and 1s \cite{Katoch2021}.
Each unit of information (also called a \textit{gene}) corresponds to one binary
digit (\textit{bit}).
%
The main advantage of binary encoding is the ability to use common and
well-researched crossover and mutation operators \cite{Katoch2021}.
However, these strategies lead to invalid representations, which
would need to be repaired \cite{Beligiannis2009}. Such repair strategies are
used in practice but pose the risk of introducing too much genetic information
which is from neither of the parents \cite{Affenzeller2009,Beligiannis2009}.
%
Furthermore, utilizing this encoding requires converting solution candidates
into binary form \cite{Katoch2021}. Depending on the complexity of the problem
this might not be feasible and thus require a different encoding.

Other well-known encoding schemes are \textit{decimal} and \textit{hexadecimal}
encoding. They work analogous to binary encoding except for using decimal and
hexadecimal digits respectively \cite{Katoch2021}.

\subsubsection{Value Encoding}
Value encoding is similar to binary encoding, as it also represents chromosomes
as strings of values. In contrast to binary encoding, these values can be
floating point numbers, integers or characters \cite{Katoch2021}.
This encoding scheme is mainly used for finding the optimal weights in a
neural network \cite{Katoch2021}.

\subsubsection{Permutation Encoding}
The permutation encoding method is commonly used in ordering problems
\cite{Katoch2021}. Similar to the encodings mentioned before, a chromosome
is made up of an array of values, but as the name suggests, the position in
the array encodes the order of the values in the context of an ordering problem
\cite{Katoch2021,Affenzeller2009}. Given that the objects of the ordering
problem are unique, this implies that the values in the array are unique too
\cite{Affenzeller2009}.

\subsubsection{Matrix Encoding}
Matrix encoding is a technique used in genetic algorithms where solutions are
represented as matrices (two-dimensional arrays) rather than as one-dimensional
arrays. This encoding is particularly useful for problems that
naturally map to a two-dimensional structure, such as scheduling, graphs
(as adjacency matrix) layout design, or certain combinatorial problems
\cite{Affenzeller2009}.



%%% Fitness Function %%%
\subsection{Fitness Function}
\enquote{In genetic algorithms a fitness function assigns a score to each
individual in a population; this fitness value indicates the quality of the
solution represented by the individual} \cite{Affenzeller2009}.
\enquote{Evaluating the fitness function for each individual should be
relatively fast due to the number of times it will be invoked}
\cite{Affenzeller2009}.
Consequently, it is arguably the most crucial component of a genetic algorithm,
and it is the only chance to steer the process of genetic evolution in
accordance with the desired optimization intentions
\cite{Beligiannis2009,kinnear1994perspective}.
Especially in the context of constrained optimization problems with multiple
objectives (e.g. hard and soft constraints), the fitness function must be
carefully designed to convey the correct optimization target for solving the
problem at hand \cite{Beligiannis2009,Carr2014}.
Timetabling problems usually pose multiple objectives in form of hard and
soft constraints \cite{Beligiannis2009}. These differ in their severity:
hard constraints must be satisfied in order for the solution to represent a
valid timetable, soft constraints on the other hand must not be satisfied and
only contribute to the quality of the solution \cite{Beligiannis2009}.

As previously stated, the design of the fitness function heavily depends on the
employed encoding scheme. The encoded data of a solution candidate serves as
the input value utilized by the fitness function to calculate the fitness of a
chromosome \cite{Affenzeller2009}. Although there is no universal recipe for
designing fitness functions, because they are highly domain-specific,
there are some methods that can be used as a starting point.
A prevalent method is to utilize a weighted sum as the foundation of a
multi-objective fitness function. Furthermore, such a function can be enhanced
through the incorporation of a penalty function, which accounts for constraint
violations at a specific weight per constraint \cite{Beligiannis2009}.

% OPTIONAL: Another option for multi-objective GAs is a Pareto-based fitness
%           function \cite{Katoch2021}.


%%% Initial Population %%%
\subsection{Initial Population}
Once an appropriate encoding and a fitness function have been established,
the initial step in the actual execution of the algorithm is to generate an
initial population \cite{Affenzeller2009}.
The initial population can be generated in two ways: randomly or heuristically.
If the problem's difficulty lies not in finding valid solutions, but in finding
the optimal solution, then heuristic initialization may be a beneficial
approach, as it could facilitate the evolution of the population.
However, in cases where finding a valid solution is already a significant
challenge, heuristics are not a viable option. In such instances, the initial
population must be created randomly \cite{Affenzeller2009}.

\subsection{Selection}
In the selection phase of a genetic algorithm, chromosomes are selected for
mating (\textit{crossover}) \cite{Affenzeller2009}.
The prerequisite for this phase of the genetic algorithm is, that the
fitness of each chromosome in the population has been evaluated
\cite{Affenzeller2009}.
At present, the most commonly employed selection techniques are roulette wheel,
rank, tournament, Boltzmann, and stochastic universal sampling
\cite{Katoch2021}.
The following sections present a brief overview of selected methods.

\subsubsection{Roulette Wheel}
The roulette wheel selection method is also called proportional selection
and works by assigning each individual a probability for reproduction according
to its fitness relative to the whole population \cite{Affenzeller2009}.
The expected value of the $i$-th chromosome to be selected for reproduction
is therefore $p_i = \frac{f_i}{\overline{f}}$ with $f_i$ denoting the fitness
of the $i$-th chromosome and $\overline{f}$ representing the average fitness
of all individuals in the population \cite{Affenzeller2009}.
\enquote{Therefore, each individual of the population is represented by a
space proportional to its fitness}\cite{Affenzeller2009} on an imaginary
roulette wheel.
\enquote{This wheel is then rotated randomly to select specific solutions that
will participate in formation of the next generatoin}\cite{Katoch2021}.

\subsubsection{Rank Selection}
\enquote{Rank selection is the modified form of Roul-ette Wheel selection.
It utilizes the ranks instead of fitness value}.
See \cite{Affenzeller2009}.
A possible approach of realizing this selection method is by ordering the
individuals according to their fitness and add copies of individuals in a way
that the best individual receives a pre-determined multiple number of copies
the worst one receives \cite{Affenzeller2009}.

Using this selection strategy reduces the dominating effect of outstanding fit
individual, but in turn distorts the difference between similarly fit
individuals, which increases the selection pressure in stagnant populations
\cite{Affenzeller2009}.
Compared to Roulette Wheel selection it reduces the chances of premature
convergence towards a local optimum \cite{Katoch2021}.

\subsubsection{Tournament Selection}
There are numerous variants of this selection method \cite{Affenzeller2009}.
The most common one is $k$-tournament selection where $k$ individuals are
randomly selected from a population and the fittest individual of the selected
ones is considered for reproduction \cite{Affenzeller2009}.
By choosing the tournament size $k$ appropriately, the selection pressure
can be easily scaled \cite{Affenzeller2009}.

% \subsubsection{Bolzmann}
% See \cite{Katoch2021}.

% \subsubsection{Comparison of selection techniques}
% See table 3 in \cite{Katoch2021}

%%% Crossover %%%
\subsection{Crossover}
Crossover is the genetic operator which performs the actual mating of
individuals selected during the selection phase \cite{Beligiannis2009}.
Given the close relation between the encoding scheme and the crossover operator,
certain crossover operators may not be compatible with some encodings in context
of the problem at hand \cite{Affenzeller2009}.

\subsubsection{Single Point}
The single point crossover method cuts each parent chromosomes into a head and
tail section. For this a random position is chosen at which both chromosomes
are cut \cite{Affenzeller2009}.
For a chromosome using binary encoding for example, this translates to
splitting the array used to represent the chromosome into two sections.
The tail sections are then swapped producing two new individuals
\cite{Affenzeller2009}.

\subsubsection{Multiple Point}
Similar to the single point crossover method, the multipoint crossover
cuts the parent chromosomes into sections. In contrast to the single point
crossover, and as the name suggests, the multipoint crossover method
uses multiple random cuts instead of a single one
\cite{Affenzeller2009,Katoch2021}. 

\subsubsection{Uniform Crossover}
Uniform crossover uses a randomly generated crossover mask, which contains
information about what parent chromosome provides certain genes to the
offspring \cite{Affenzeller2009}. This information could for example be:
\enquote{the first and second gene (e.g. first and second value in the array)
are taken from the first parent, the third gene is taken from the second
parent}.
To yield two children from the crossover operation, the mask can be inverted.
This process is equal to randomly swapping genes (at the same position) between
the parents and taking the resulting chromosomes as offspring \cite{Katoch2021}.


\subsubsection{Partially matched crossover}
Partially matched crossover is the most commonly used crossover operator,
as it performs better than most of the other operators \cite{Katoch2021}.
This crossover technique works by randomly choosing a continuous part of genes
from one parent, and swapping it with the corresponding genes (at the same
position) from the other parent chromosome \cite{Katoch2021}.
The left out genes are simply copied to the offspring chromosomes, except of
genes with values which are contained in the parts that were swapped between
the parents. The swapped section of genes denotes a mapping which is used to
map these values to the offspring chromosomes instead of simply copying them
\cite{Katoch2021}.

\begin{figure}[h]
  \includegraphics[scale=0.14]{assets/partially-matched-crossover.png}
  \caption{Partially matched crossover visualization \cite{Katoch2021}}
  \Description{Visualization of partially matched crossover operation}
\end{figure}


\subsubsection{Order crossover}
Order crossover copies one (or more) parts of the parent to the offspring
and fills the remaining space with genes from the respective present, which
are not present in the copied section \cite{Katoch2021}.

% \subsubsection{Shuffle crossover}
% See \cite{Katoch2021}.

% \subsubsection{Comparison of different crossover techniques}
% See table 4 \cite{Katoch2021}.

%%% Mutation %%%
\subsection{Mutation}
The mutation operator is used on the offspring created by the crossover
operation, to allow undirected jumps to slightly different areas of the search
space \cite{Affenzeller2009}. This procedure maintains genetic diversity
throughout generations and helps in efficiently exploring the search space
\cite{Katoch2021, Affenzeller2009}.

The actual implementation of the mutation operator greatly depends on the chosen
encoding, because mutating a chromosome could potentially lead to an invalid
solution candidate depending on how the encoding is designed.

Well-known mutation operators are displacement, simple inversion and scramble
mutation.

\subsubsection{Displacement Mutation (DM)}
The displacement mutation operator selects a random section from a chromosome
and moves it to another position on the chromosome \cite{Katoch2021}.
This operation does not change the sequence of the genes not included in the
moved section.

\subsubsection{Simple Inversion Mutation (SIM)}
For simple inversion mutation a random section is selected from a chromosome.
The order of the genes in this section is then reversed \cite{Katoch2021}.
This mutation can be further enhanced by also moving the section to another
position within the chromosome (similar to displacement mutation)
\cite{Katoch2021}.

\subsubsection{Scramble Mutation (SM)}
The scramble mutation is very similar to the simple inversion mutation with the
single difference of not inverting but shuffling the genes in the randomly
selected part of the chromosome \cite{Katoch2021}.


%%% Evaluation %%%
\subsection{Evaluation}
For the sake of completeness, the evaluation is listed here as separate phase,
even though this is not common in the researched literature. The evaluation
phase serves as the final step after successful application of the crossover
and mutation operations, in which the fitness of the new individuals
must be calculated in order to continue with the genetic algorithm.

%%% Replacement %%%
\subsection{Replacement}
After the current generation has reproduced in the selection, cross-over and
mutation phase, which created new offspring, the question arises as to which
of the new solution candidates should become members of the next generation
\cite{Affenzeller2009}. In context of evolution the replacement strategy
determines the life span of the individuals and substantially influences
the convergence behavior of the algorithm \cite{Affenzeller2009}.
The following schemes are possible replacement strategies for genetic
algorithms:

\subsubsection{Generational Replacement}
\cite{Affenzeller2009}
As the name already suggests, the generational replacement strategy simply
replaces the current population with the newly created offspring.
This process may result in a decrease of the fitness of the fittest individual
in the population at some stages of evolution \cite{Affenzeller2009}.

\subsubsection{Elitism}
With an elitism method of generation replacement, the best individual
(or the $n$ best individuals) of the previous generation are retained for
the next generation \cite{Affenzeller2009, Katoch2021}.
This theoretically allows individuals to be immortal and might lead to
premature convergence \cite{Affenzeller2009}.
The special case of only retaining the best individual is also called
\enquote{golden cage model} ($n$-elitism with $n = 1$) \cite{Affenzeller2009}.
In case the mutation operator is applied to the elite individuals to prevent
premature convergence, the replacement strategy is called \enquote{weak elitism}
\cite{Affenzeller2009}.

\subsubsection{Delete-$n$-last}
The $n$ weakest individuals are replaced by $n$ descendants
\cite{Affenzeller2009}. If $n$ is much smaller than the population size, this
strategy is known as steady-state replacement scheme \cite{Affenzeller2009}.
For $n = 1$, the changes between the old and new generations are minimal, while
choosing $n$ equal to the size of the population represents the previously
discussed generational replacement strategy \cite{Affenzeller2009}.


\subsubsection{Delete-$n$}
In contrast to the delete-n-last replacement strategy, this approach replaces
$n$ arbitrarily chosen individuals from the old generation rather than the
weakest ones \cite{Affenzeller2009}.
While this reduces the convergence speed of the algorithm, it also helps to
avoid premature convergence, balancing between elitism and weak elitism
\cite{Affenzeller2009}.

\subsubsection{Tournament Replacement}
Tournament replacement is similar to the equally named selection strategy.
In this replacement scheme competitions are run between sets of individuals
from the old population and their offspring \cite{Affenzeller2009}.
The winners of these tournaments become part of the new population
\cite{Affenzeller2009}.


%%% Termination %%%
\subsection{Termination}
As previously stated, the evolutionary process in genetic algorithms is
an infinite loop that requires a termination criterion to halt.
The desired termination constraint may vary depending on the problem and the
context in which the algorithm is used in.
One straightforward approach is to simply stop the genetic algorithm after a
certain number of generations has been reached \cite{Beligiannis2009}.
Another widely used method is to terminate the algorithm when the fitness value
of the best individual has not changed over a predefined number of
generations \cite{Carr2014}.


%% Advanced Techniques ------------------------------------------------------ %%
\section{Advanced Techniques}
In the field of genetic programming, it is common practice to adapt existing
methods to fit one's own use case. This has led to a steady development of new
approaches to improve genetic search in general.
While it is beyond the scope of this paper to provide an exhaustive overview
of the many branches of advanced genetic search,
the following sections present a selection of important in regard to solving
timetabling problems.

%%% Direct and Indirect Encoding %%%
\subsection{Direct and Indirect Encoding}
Genetic algorithms can be classified into two primary categories based on the
employed encoding scheme: \textit{direct} and \textit{indirect}
\cite{Thanh2007}.
In a direct encoding, the chromosome encodes all features of a solution
candidate, meaning that the whole search space is encoded
\cite{Thanh2007,Goos2002}.
Depending on the problem domain, this means, that chromosomes may also
represent invalid solution candidates. Therefore, direct encodings are prone
to hard constraint violations on crossover and mutation operations, which
requires applying additional mechanisms to find feasible solutions
\cite{Goos2002}.
One possible solution is to repair these invalid
chromosomes by applying a repair function that uses domain-specific
heuristics to transform the chromosome to a valid state, with the downside of
introducing genetic information not related to either of the parents
\cite{Beligiannis2009,Affenzeller2009}.

In contrast to a direct representation, an indirect (or \textit{implicit})
encoding only \textit{partially} encodes a solution candidate \cite{Thanh2007}.
One advantage of not encoding all information of a solution is, that
this restricts the search space the algorithm has to explore \cite{Goos2002}.
Furthermore, by using an indirect encoding, compliance with hard (and even
soft) constraints can be guaranteed, if the encoding is designed to
only represent valid solutions \cite{Goos2002}.

School timetabling problems are highly constrained, hence indirect
encodings have been successfully applied to such problems \cite{Goos2002}.


%%% Custom genetic operators %%%
\subsection{Custom genetic operators}
Especially for solving more complex solutions, like creating the forementioned
school timetable with many constraints, customized variants of genetic
operators may be necessary \cite{Beligiannis2009,Almeida2015}.
An example for such a custom operator is presented in \cite{Beligiannis2009}.
Their crossover operator is derived from a typical uniform crossover, but
it is adapted to the problem domain to not cause problems with a teacher's
schedule \cite{Beligiannis2009}.
Another potential application of such custom genetic operators could also be
the prevention of producing infeasible solutions, when using encoding schemes
that do not rule such invalid chromosomes out by design \cite{Elliman1995}.
%
Similarly to the custom crossover operator mentioned above,
mutation operators must also be adapted according to the chosen encoding
scheme \cite{Almeida2015}.

% \cite[8]{Affenzeller2009}
% You have to know what you do \cite{???}.


%%% Selection Pressure %%%
\subsection{Selection Pressure}
In the context of genetic algorithms, selection pressure refers to the
intensity with which the algorithm favors the fittest individuals during the
selection process for reproduction \cite{back1994selective, Affenzeller2009}.
%
When selection pressure is high, the algorithm strongly favors the best
individuals in the population. These individuals are more likely to be selected
for reproduction, leading to a quicker convergence towards optimal or
near-optimal solutions. However, if the pressure is too high, it might cause
premature convergence, where the population loses diversity and gets stuck in
local optima \cite{back1994selective}.

Conversely, when selection pressure is low, the algorithm less strongly favors
the fittest individuals. This allows for a more diverse set of individuals
to be selected for crossover. This helps to maintain genetic diversity within
the population and can avoid premature convergence. However, if the pressure
is too low, the algorithm may converge very slowly or struggle to find optimal
solutions efficiently \cite{back1994selective}.

Consequently, the selection pressure generated by the utilized selection method
is always a compromise between convergence speed and avoiding premature
convergence. It appears, that a dynamic intervention in the evolutionary process
to adapt the selection process and the associated selection pressure would
result in an improvement of the algorithm. This is exactly the approach taken
by the offspring selection method explained in the following paragraph.


%%% Offspring Selection (OS) %%%
\subsection{Offspring Selection}
Offspring selection (OS) is a self-adaptive selection pressure steering method
\cite{Affenzeller2009}.
Contrary to what the name suggests, this method does not replace previously
presented selection methods, such as roulette-wheel or linear-rank schemes.
Instead, a second selection step is introduced \cite{Affenzeller2009}.
After the first selection step has been executed (for example roulette-wheel
selection) and the crossover operation has been applied to the selected
chromosomes, a further selection -- the offspring selection -- is applied
\cite{Affenzeller2009}.

The offspring selection considers the fitness of the individuals resulting from
crossover.
To assure the genetic search mainly progresses with successful offspring,
the newly introduced selection step guarantees that a sufficient number of
children surpass their parents' fitness \cite{Affenzeller2009}.
The success ratio ($SuccRatio \in [0, 1]$) controls the proportion of
individuals in the next generation, with better fitness than their parents
\cite{Affenzeller2009}.

This inevitably leads to the following question:
\enquote{Is a child better than its parents, if it surpasses the fitness of the
weaker parent, the better parent, or some kind of weighted average of both?}
\cite{Affenzeller2009}.
To answer this question the offspring selection method introduces a comparison
factor ($CompFactor \in [0, 1]$), inspired by simulated annealing. This factor
sets a fitness threshold between the worse and better parent. Early in the
process, offspring only need to surpass the fitness of the weaker parent to
be considered \textit{better}. As the algorithm progresses, this threshold
increases towards the fitness of the better parent, facilitating a broader
search initially and a more focused search later \cite{Affenzeller2009}.
% affenzeller s.70
The gradual increase of the comparison factor adjusts the selection pressure
throughout the genetic search process, starting with a low selection pressure
to prevent premature convergence and steadily increasing the pressure to
not suffer from long runtimes until the search converges \cite{Affenzeller2009}.


%%% Parallel Genetic Algorithms %%%
\subsection{Parallel Genetic Algorithms}
Genetic algorithms are well suited for parallelization. There are various
methods of implementing these, some of which require fundamental changes to the
algorithm and others do not \cite{Affenzeller2009}.
%
Concepts for parallel genetic algorithms fall into three categories:
global parallelization, coarse-grained parallel GAs and fine-grained parallel
GAs. The most popular for practical applications is the coarse-grained model,
also known as the island model \cite{Affenzeller2009}.

\subsubsection*{Global Parallelization}
In global parallelization, a single population is used, and selection involves
all individuals. This method retains the same qualitative properties as a
sequential GA, with the primary parallelized operation being the evaluation of
individual fitness. A master node distributes and collects workloads from slave
processors, making this model efficient when fitness evaluation is the primary
runtime bottleneck (see \autoref{tab:parallel-ga-global})\cite{Affenzeller2009}.
\begin{figure}[h]
  \includegraphics[scale=0.22]{assets/parallel-ga-global.png}
  \caption{
    Global parallelization: Single population (left) and the corresponding
    master-slave model (right) \cite{Affenzeller2009}.
  }
  \Description{Visualization of global parallelization concept}
  \label{tab:parallel-ga-global}
\end{figure}

\subsubsection*{Coarse-grained parallel genetic algorithms}
Coarse-grained parallel GAs divide the population into subpopulations
(called \textit{islands} or \textit{demes}) that evolve mostly in isolation,
occasionally exchanging individuals during migration phases.
This model introduces significant changes to the algorithm structure,
differing from sequential genetic algorithms \cite{Affenzeller2009}.
The main idea is that isolated demes will converge to different regions of the
solution space, with migration and recombination combining relevant solution
parts (see \autoref{tab:parallel-ga-coarse})\cite{Affenzeller2009}.
Coarse-grained parallel genetic algorithms are widely used due to their
ease of implementation and therefore the most popular method of
parallelizing genetic algorithms \cite{Affenzeller2009}.
\begin{figure}[h]
  \includegraphics[scale=0.24]{assets/parallel-ga-coarse.png}
  \caption{
    Population structure of a coarse-grained parallel genetic algorithm
    \cite{Affenzeller2009}.
  }
  \Description{
    Visualization of the population structure in a coarse-grained parallel
    genetic algorithm
  }
  \label{tab:parallel-ga-coarse}
\end{figure}

\subsubsection*{Fine-grained parallel genetic algorithms}
Fine-grained parallel genetic algorithms involve many small demes which are
part of one spatially distributed population \cite{Affenzeller2009}.
The idea behind this is that individuals are spread throughout the
global population like molecules in a diffusion process, with recombination
restricted to local neighborhoods (see \autoref{tab:parallel-ga-fine})
\cite{Affenzeller2009}.
\begin{figure}[h]
  \includegraphics[scale=0.24]{assets/parallel-ga-fine.png}c
  \caption{
    Population structure of a fine-grained parallel genetic algorithm
    with a cellular model \cite{Affenzeller2009}.
  }
  \Description{
    Visualization of the population structure in a fine-grained parallel
    genetic algorithm using a cellular model
  }
  \label{tab:parallel-ga-fine}
\end{figure}


%% Discussion --------------------------------------------------------------- %%
% \newpage
\section{Discussion}
This chapter presents and discusses the results of the conducted literature
analysis. It focuses on presenting the genetic algorithms found in literature
and their properties in a morphological box, which was chosen to easily
examine which combinations of traits have been used successfully to date,
which have received lesser attention, and which new combinations offer potential
for future research.

\autoref{tab:morph-box} shows the forementioned overview of genetic algorithms
found in the literature research, and their main characteristics.

% Morphologischer Kasten
\begin{table*}[]
\begin{adjustwidth}{-2cm}{-2cm}
  \centering
  
  \begin{tabular}{|l|l|l|l|l|l|l|l|l|l|}
  \hline
  % Headline Row
  \textbf{Problem}&
  \textbf{Encoding}&
  \begin{tabular}[c]{@{}l@{}}
    \textbf{Fitness}\\
    \textbf{Function}
  \end{tabular}&
  \textbf{Selection}&
  \textbf{Crossover}&
  \textbf{Mutation}&
  \begin{tabular}[c]{@{}l@{}}
    \textbf{Population}\\
    \textbf{Initialization}
  \end{tabular}&
  \textbf{Elitism}&
  \textbf{Note}&
  \textbf{Source} \\
  \hline

  % ----------------------------------------------------------------------------
  % 1. Row
    % Problem
    ETT&

    % Encoding
    Direct&

    % Fitness Function
    ?&

    % Selection
    ?&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      Custom heuristic\\
      (ensuring valid\\
      solutions)
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      Custom (prevents\\
      infeasible results)\\
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      Heuristic\\
      (only feasible\\
      solutions)\\
    \end{tabular}&

    % Elitism
    ?&

    % Note
    Hybrid&

    % Source
    \cite{Elliman1995} (1995)\\

    \hline


  % ----------------------------------------------------------------------------
  % 2. Row
    % Problem
    HSTP&

    % Encoding
    \begin{tabular}[c]{@{}l@{}}
      Direct (array)
    \end{tabular}&

    % Fitness Function
    \begin{tabular}[c]{@{}l@{}}
      Penalty points
    \end{tabular}&

    % Selection
    \begin{tabular}[c]{@{}l@{}}
      Roulette wheel
    \end{tabular}&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      One-, two-point\\
      and uniform\\
      (with repair)
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      Hybrid with\\
      repair function
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      Random
    \end{tabular}&

    % Elitism
    \begin{tabular}[c]{@{}l@{}}
      Yes
    \end{tabular}&

    % Note
    \begin{tabular}[c]{@{}l@{}}
      Uses domain\\
      knowledge
    \end{tabular}&

    % Source
    \cite{Goos2002} (2002)\\

    \hline

  % ----------------------------------------------------------------------------
  % 3. Row
    % Problem
    UCTP&

    % Encoding
    \begin{tabular}[c]{@{}l@{}}
      Permutation\\
      (indirect)\\
      (2D matrix)
    \end{tabular}&

    % Fitness Function
    \begin{tabular}[c]{@{}l@{}}
      Custom\\
      (encoding-based\\
      metric)
    \end{tabular}&

    % Selection
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      Two-point
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      Random swap
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      Random\\
      (with heuristic)
    \end{tabular}&

    % Elitism
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Note
    \begin{tabular}[c]{@{}l@{}}
      Genetic and\\
      heuristic\\
      algorithm
    \end{tabular}&

    % Source
    \cite{Thanh2007} (2007)\\

    \hline

  % ----------------------------------------------------------------------------
  % 4. Row
    % Problem
    HSTP&

    % Encoding
    \begin{tabular}[c]{@{}l@{}}
      Enumeration\\
      (direct; \\
      2D matrix)
    \end{tabular}&

    % Fitness Function
    \begin{tabular}[c]{@{}l@{}}
      Multi objective\\
      (weighted sum)
    \end{tabular}&

    % Selection
    \begin{tabular}[c]{@{}l@{}}
      Roulette wheel
    \end{tabular}&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      Dynamic, cost\\
      based operators
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      Custom
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      Random
    \end{tabular}&

    % Elitism
    \begin{tabular}[c]{@{}l@{}}
      Yes
    \end{tabular}&

    % Note
    \begin{tabular}[c]{@{}l@{}}
      
    \end{tabular}&

    % Source
    \cite{Beligiannis2009} (2009)\\

    \hline

  % ----------------------------------------------------------------------------
  % 5. Row
    % Problem
    HSTP&

    % Encoding
    \begin{tabular}[c]{@{}l@{}}
      Decimal\\
      (direct)
    \end{tabular}&

    % Fitness Function
    \begin{tabular}[c]{@{}l@{}}
      Multi objective\\
      (weighted sum)
    \end{tabular}&

    % Selection
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      Custom
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      Custom
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      Random
    \end{tabular}&

    % Elitism
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Note
    \begin{tabular}[c]{@{}l@{}}

    \end{tabular}&

    % Source
    \cite{Liu2011} (2011)\\

    \hline

  % ----------------------------------------------------------------------------
  % 6. Row
    % Problem
    HSTP&

    % Encoding
    \begin{tabular}[c]{@{}l@{}}
      Matrix\\
      (variable\\
      length)
    \end{tabular}&

    % Fitness Function
    \begin{tabular}[c]{@{}l@{}}
      2-step\\
      cost function\\
    \end{tabular}&

    % Selection
    \begin{tabular}[c]{@{}l@{}}
      $t$-tournament
    \end{tabular}&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      Multi-point\\
      (cut and splice)
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      Swapping\\
      (based on\\
      heuristics)
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      Random\\
      (fixed length)
    \end{tabular}&

    % Elitism
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Note
    \begin{tabular}[c]{@{}l@{}}
      Hyper-\\
      heuristic
    \end{tabular}&

    % Source
    \cite{Raghavjee2015} (2015)\\

    \hline

  % ----------------------------------------------------------------------------
  % 7. Row
    % Problem
    UCTP&

    % Encoding
    \begin{tabular}[c]{@{}l@{}}
      Direct
    \end{tabular}&

    % Fitness Function
    \begin{tabular}[c]{@{}l@{}}
      Multi-objective\\
      (weighted sum)
    \end{tabular}&

    % Selection
    \begin{tabular}[c]{@{}l@{}}
      Tournament
    \end{tabular}&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      Uniform
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      Random move in\\
      neighborhood
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      Random\\
      (uniform\\
      distribution)
    \end{tabular}&

    % Elitism
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Note
    \begin{tabular}[c]{@{}l@{}}
      Hybrid =\\
      GA + local\\
      search
    \end{tabular}&

    % Source
    \cite{Badoni2015} (2015)\\

    \hline

  % ----------------------------------------------------------------------------
  % 8. Row
    % Problem
    UCTP&

    % Encoding
    \begin{tabular}[c]{@{}l@{}}
      Direct\\
      (3D matrix)
    \end{tabular}&

    % Fitness Function
    \begin{tabular}[c]{@{}l@{}}
      Multi objective\\
      (weighted sum)
    \end{tabular}&

    % Selection
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      Custom
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      Repair function\\
      as mutation
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      Random
    \end{tabular}&

    % Elitism
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Note
    \begin{tabular}[c]{@{}l@{}}

    \end{tabular}&

    % Source
    \cite{Almeida2015} (2015)\\

    \hline

  % ----------------------------------------------------------------------------
  % 9. Row
    % Problem
    UCTP&

    % Encoding
    \begin{tabular}[c]{@{}l@{}}
      Permutation
    \end{tabular}&

    % Fitness Function
    \begin{tabular}[c]{@{}l@{}}
      Weighted\\
      penalty func.
    \end{tabular}&

    % Selection
    \begin{tabular}[c]{@{}l@{}}
      Roulette wheel
    \end{tabular}&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      Cycle cross-\\
      over
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      Swap
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      Random
    \end{tabular}&

    % Elitism
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Note
    \begin{tabular}[c]{@{}l@{}}

    \end{tabular}&

    % Source
    \cite{Gomes2016} (2016)\\

    \hline

  % ----------------------------------------------------------------------------
  % 10. Row
    % Problem
    UCTP&

    % Encoding
    \begin{tabular}[c]{@{}l@{}}
      Direct
    \end{tabular}&

    % Fitness Function
    \begin{tabular}[c]{@{}l@{}}
      Multi-objective\\
      (weighted sum)
    \end{tabular}&

    % Selection
    \begin{tabular}[c]{@{}l@{}}
      Custom\\
      (gender based)
    \end{tabular}&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      Single-point
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      Custom\\
      (local search)
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Elitism
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Note
    \begin{tabular}[c]{@{}l@{}}
      Parallel;\\
      GPU accel-\\
      erated
    \end{tabular}&

    % Source
    \cite{yousef2016gpu} (2016)\\

    \hline

  % ----------------------------------------------------------------------------
  % 11. Row
    % Problem
    UCTP&

    % Encoding
    \begin{tabular}[c]{@{}l@{}}
      Indirect\\
      (2D matrix)
    \end{tabular}&

    % Fitness Function
    \begin{tabular}[c]{@{}l@{}}
      MILP objective\\
      function
    \end{tabular}&

    % Selection
    \begin{tabular}[c]{@{}l@{}}
      $2$-tournament
    \end{tabular}&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      Two-point
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      Two-step:\\
      random swap;\\
      then heuristic
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      Random and\\
      directed
    \end{tabular}&

    % Elitism
    \begin{tabular}[c]{@{}l@{}}
      Yes
    \end{tabular}&

    % Note
    \begin{tabular}[c]{@{}l@{}}
      Hybrid =\\
      GA + local\\
      search
    \end{tabular}&

    % Source
    \cite{Feng2017} (2017)\\

    \hline

  % ----------------------------------------------------------------------------
  % 12. Row
    % Problem
    UCTP&

    % Encoding
    \begin{tabular}[c]{@{}l@{}}
      Direct\\
      (2D matrix)
    \end{tabular}&

    % Fitness Function
    \begin{tabular}[c]{@{}l@{}}
      Multi-objective\\
      (soft-constraints\\
      and robustness)
    \end{tabular}&

    % Selection
    \begin{tabular}[c]{@{}l@{}}
      Roulette wheel\\
      and random\\
      (both used)
    \end{tabular}&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      Partially matched\\
      with repair func.\\
      and hill climb
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      Hill climb\\
      operators (swap\\
      and move)
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      Heuristic (const-\\
      raint program-\\
      ming based)
    \end{tabular}&

    % Elitism
    \begin{tabular}[c]{@{}l@{}}
      Yes\\
      (rank)
    \end{tabular}&

    % Note
    \begin{tabular}[c]{@{}l@{}}

    \end{tabular}&

    % Source
    \cite{Akkan2018} (2018)\\

    \hline

  % ----------------------------------------------------------------------------
  % 13. Row
    % Problem
    UCTP&

    % Encoding
    \begin{tabular}[c]{@{}l@{}}
      Direct\\
      (3 matrices)
    \end{tabular}&

    % Fitness Function
    \begin{tabular}[c]{@{}l@{}}
      Multi-objective\\
      (weighted and\\
      squared sum)
    \end{tabular}&

    % Selection
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      Multi-point
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      Guided mutation\\
      with repair func.
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      Random
    \end{tabular}&

    % Elitism
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Note
    \begin{tabular}[c]{@{}l@{}}
      Hybrid =\\
      GA + guided\\
      search
    \end{tabular}&

    % Source
    \cite{Matias2018fair} (2018)\\

    \hline

  % ----------------------------------------------------------------------------
  % 14. Row
    % Problem
    UCTP&

    % Encoding
    \begin{tabular}[c]{@{}l@{}}
      Enumeration\\
      (direct)
    \end{tabular}&

    % Fitness Function
    \begin{tabular}[c]{@{}l@{}}
      Dynamic\\
      multi-level
    \end{tabular}&

    % Selection
    \begin{tabular}[c]{@{}l@{}}
      Roulette wheel
    \end{tabular}&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      Customized\\
      multi-point
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      Custom\\
      multi-level
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      Greedy\\
      (minimizes hard\\
      constraint\\
      violations)
    \end{tabular}&

    % Elitism
    \begin{tabular}[c]{@{}l@{}}
      Yes\\
      ($1+m$)
    \end{tabular}&

    % Note
    \begin{tabular}[c]{@{}l@{}}

    \end{tabular}&

    % Source
    \cite{gozali2020multidepth} (2020)\\

    \hline

  % ----------------------------------------------------------------------------
  % 15. Row
    % Problem
    UCTP&

    % Encoding
    \begin{tabular}[c]{@{}l@{}}
      Enumeration\\
      (direct; 3D\\
      matrix)
    \end{tabular}&

    % Fitness Function
    \begin{tabular}[c]{@{}l@{}}
      Penalty points\\
      (for hard\\
      constraint\\
      violations)
    \end{tabular}&

    % Selection
    \begin{tabular}[c]{@{}l@{}}
      Roulette wheel
    \end{tabular}&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      Multi-point\\
      (directed by\\
      constraint\\
      violation)
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      3-step:\\
      move, swap,\\
      compare
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      Greedy
    \end{tabular}&

    % Elitism
    \begin{tabular}[c]{@{}l@{}}
      Yes
    \end{tabular}&

    % Note
    \begin{tabular}[c]{@{}l@{}}
      Parallel\\
      (island\\
      model)
    \end{tabular}&

    % Source
    \cite{gozali2020islandmodel} (2020)\\

    \hline


  % ----------------------------------------------------------------------------
  % 16. Row
    % Problem
    ?&

    % Encoding
    \begin{tabular}[c]{@{}l@{}}
      Binary\\
      (direct)
    \end{tabular}&

    % Fitness Function
    \begin{tabular}[c]{@{}l@{}}
      Custom
    \end{tabular}&

    % Selection
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      Random
    \end{tabular}&

    % Elitism
    \begin{tabular}[c]{@{}l@{}}
      Yes\\
      (best\\
      $10\%$)
    \end{tabular}&

    % Note
    \begin{tabular}[c]{@{}l@{}}

    \end{tabular}&

    % Source
    \cite{elliot2020enhanced} (2020)\\

    \hline

  % ----------------------------------------------------------------------------
  % 17. Row
    % Problem
    ETP&

    % Encoding
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Fitness Function
    \begin{tabular}[c]{@{}l@{}}
      Multi objective\\
      (normalized sum)
    \end{tabular}&

    % Selection
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Elitism
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Note
    \begin{tabular}[c]{@{}l@{}}

    \end{tabular}&

    % Source
    \cite{tung2021genetic} (2021)\\

    \hline

  % ----------------------------------------------------------------------------
  % 18. Row
    % Problem
    UCTP&

    % Encoding
    \begin{tabular}[c]{@{}l@{}}
      Dynamic\\
      length\\
      (direct)
    \end{tabular}&

    % Fitness Function
    \begin{tabular}[c]{@{}l@{}}
      Amount of\\
      constraint\\
      violations
    \end{tabular}&

    % Selection
    \begin{tabular}[c]{@{}l@{}}
      Roulette wheel\\
      (with fitness\\
      threshold)
    \end{tabular}&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      Single-point
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      ?
    \end{tabular}&

    % Elitism
    \begin{tabular}[c]{@{}l@{}}
      Yes\\
      (during\\
      select.)
    \end{tabular}&

    % Note
    \begin{tabular}[c]{@{}l@{}}

    \end{tabular}&

    % Source
    \cite{Alnowaini2021} (2021)\\

    \hline

  % ----------------------------------------------------------------------------
  % 19. Row
    % Problem
    UCTP&

    % Encoding
    \begin{tabular}[c]{@{}l@{}}
      Binary\\
      (direct)
    \end{tabular}&

    % Fitness Function
    \begin{tabular}[c]{@{}l@{}}
      Multi-objective\\
      (weighted sum)
    \end{tabular}&

    % Selection
    \begin{tabular}[c]{@{}l@{}}
      Tournament
    \end{tabular}&

    % Crossover
    \begin{tabular}[c]{@{}l@{}}
      Multi-point
    \end{tabular}&

    % Mutation
    \begin{tabular}[c]{@{}l@{}}
      Custom\\
      (class mutation)
    \end{tabular}&

    % Population Initialization
    \begin{tabular}[c]{@{}l@{}}
      Heuristic\\
      (only feasible\\
      solutions)
    \end{tabular}&

    % Elitism
    \begin{tabular}[c]{@{}l@{}}
      Yes
    \end{tabular}&

    % Note
    \begin{tabular}[c]{@{}l@{}}
      Uses repair\\
      function
    \end{tabular}&

    % Source
    \cite{Mahlous2023} (2023)\\

    \hline

  \end{tabular}

  \caption{
    Morphological box presenting genetic algorithms with their main
    characteristics
  }
  \label{tab:morph-box}
\end{adjustwidth}
\end{table*}


% Trends auswerten:
% - häufigste selektionsmethode
% - beliebtestes encoding
% - ... für jede eigenschaft?
% - parallelität spielt kaum ein Thema -> birgt aber ein riesen potential (GPU)
  % potenzial der besseren parallelisierung ggü von populären integer
  % programming methoden. das könnte der game changer sein % gerade bei
  % parallelisierung mit GPUs

% - Der morphologische Kasten identifiziert verschiedene Kombinationen von
  % Eigenschaften, die bisher wenig oder gar nicht untersucht wurden.
  % Insbesondere die Kombination von adaptiven Selektionsmethoden mit
  % fortschrittlichen Mutationsmechanismen bietet ein großes Potenzial für
  % zukünftige Forschungen. Diese neuen Ansätze könnten zu effizienteren und
  % effektiveren Lösungen für das educational timetabling führen.
  %
  % +++ und PARALLELISIERUNG !!!

% - Untersuchung der Auswirkung weiterer parameter (Mutationswarhscheinlichkeit
%   usw. auf den Selection Pressure)

The application of genetic algorithms in the field of educational timetabling
has demonstrated significant potential in addressing complex optimization
problems. The following paragraphs discuss the various methodologies and
strategies employed in the studies reviewed, highlighting both the prevalent
and less commonly used techniques.
The aim is to provide a comprehensive understanding of the current landscape,
identify trends, and suggest potential areas for future research.

\subsection{Prevalent Techniques}
Several methods and strategies have emerged as popular choices among researchers
working on educational timetabling problems. Direct encoding, multi-objective
fitness functions, and the use of roulette wheel selection are some of the most
frequently utilized techniques.

\subsubsection{Encodings}
Direct encoding methods are widely adopted across many studies. This approach
involves representing the time-table directly in a matrix form, which simplifies
the application of genetic operators and allows for straightforward
interpretation and manipulation of solutions.
Examples include the studies by Thanh (2007, \cite{Thanh2007}),
Almeida (2015, \cite{Almeida2015}), and Akkan (2018, \cite{Akkan2018}).
This prevalence suggests that direct encoding is effective in handling the
constraints and requirements of timetabling problems.

\subsubsection{Fitness Functions}
The use of multi-objective fitness functions is another common strategy.
Researchers often employ a weighted sum approach to balance various objectives,
such as minimizing the number of constraint violations and maximizing
robustness. This method is evident in the works of Liu
(2011, \cite{Liu2011}), Badoni (2015, \cite{Badoni2015}), and Matias
(2018, \cite{Matias2018fair}).
Multi-objective functions provide a more holistic evaluation
of solutions, aligning well with the complex nature of educational timetabling,
which typically involves multiple competing goals.

\subsubsection{Selection Mechanisms}
Roulette wheel selection is frequently used to guide the evolution of
solutions, as seen in Goos (2002, \cite{Goos2002}), Beligiannis
(2009, \cite{Beligiannis2009}), and Gozali (2020, \cite{gozali2020islandmodel}).
This method mimics natural selection by giving higher probabilities of
selection to better-performing solutions, thus ensuring that high-quality
timetables are more likely to propagate through successive generations.

\subsubsection{Crossover and Mutation Operations}
Crossover and mutation operators are rarely used as \enquote{defined in
textbooks}. A popular choice among the reviewed algorithms is $n$-point
crossover, although it has mostly been customized to suit the utilized
encoding. For example, Thanh (2007, \cite{Thanh2007}) and Gozali
(2020, \cite{gozali2020islandmodel}) employ two-point and multi-point crossover
methods, respectively, while Goos (2002, \cite{Goos2002}) integrates repair
functions to handle infeasible offspring.

Similarly, mutation strategies often involve domain-specific heuristics to
prevent infeasible solutions. Swapping-based mutations, as utilized by
Liu (2011, \cite{Liu2011}) and Raghavjee (2015, \cite{Raghavjee2015}),
are common, as they can oftentimes be utilized to explore the solution space
without violating hard constraints.

\subsection{Less Utilized Techniques}
Despite the success of the aforementioned methods, several techniques are
notably underutilized in the reviewed literature. These include parallelism,
adaptive steering of the evolutionary process, and more sophisticated
population initialization strategies.

\subsubsection{Parallelism}
Parallel genetic algorithms offer substantial advantages in terms of
computational efficiency and solution quality by distributing the workload
across multiple processors. However, only a few studies, such as those by
Yousef (2016, \cite{yousef2016gpu}) and Gozali
(2020, \cite{gozali2020islandmodel}), have explored this approach. Given the
increasing availability of parallel computing resources, there is significant
potential for further research in this area to enhance the scalability and
performance of GAs in timetabling.

\subsubsection{Adaptive Evolutionary Strategies}
Adaptive and dynamic evolutionary strategies, which adjust parameters such as
mutation rates or selection pressures based on the current state of the
population, can improve convergence rates and solution quality.
Despite their promise, these methods are rarely implemented in the reviewed
studies. The lack of adaptive mechanisms suggests an area for future
exploration, where more responsive algorithms could lead to more efficient
search processes and better handling of diverse problem instances.

\subsubsection{Population Initialization}
Most studies rely on random or heuristic-based population initialization
methods. While these approaches are straightforward and often effective, they
may not fully exploit the potential of more sophisticated initialization
strategies. Techniques that incorporate domain knowledge or use advanced
heuristics could provide a more robust starting point, leading to faster
convergence and higher-quality solutions. This area remains largely unexplored,
as indicated by the predominant use of simpler methods in the reviewed
literature.

\subsection{Integration of Hybrid Methods}
Hybrid methods that combine genetic algorithms with other optimization
techniques, such as local search or constraint programming, have shown promise
in several studies, including those by Feng (2017, \cite{Feng2017}) and Matias
(2018, \cite{Matias2018fair}). These approaches leverage the strengths of
multiple algorithms to address different aspects of the problem more
effectively. The success of hybrid methods suggests that further integration of
complementary techniques could enhance the performance of genetic algorithms
in timetabling.



%% Conclusion --------------------------------------------------------------- %%
\section{Conclusion}
The review of genetic algorithms applied to educational timetabling reveals a
landscape dominated by well-established techniques such as direct encoding,
multi-objective fitness functions, and roulette wheel selection. While these
methods have proven effective, there is considerable potential for innovation
through the adoption of less common strategies, including parallelism, adaptive
evolutionary processes, and advanced population initialization. Future research
should focus on these underexplored areas to further enhance the capability and
efficiency of genetic algorithms in solving complex timetabling problems.
The continued integration of hybrid methods also presents a promising direction
for achieving superior results.

%% Future Work -------------------------------------------------------------- %%
\section{Future Work}
The findings from this work will serve as the basis for the author's master's
thesis, in which a genetic algorithm for a special timetabling problem will be
developed.
The examinations conducted in this paper provide information about the most
frequently used techniques of genetic search within the timetabling domain,
which will serve as a reference point for selecting the most appropriate
genetic methods for the algorithm to be developed.


%% ACKNOWLEDGEMENTS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{acks}
% To Robert, for the bagels and explaining CMYK and color spaces.
% \end{acks}

%% BIBLIOGRAPHY %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{ACM-Reference-Format}
\bibliography{main}


%% APPENDIX %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \appendix
% \section{Research Methods}


%% END %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
\endinput

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
